{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e922eb40-f560-4085-92c8-738160d43b29",
   "metadata": {},
   "source": [
    "# Modelo Open Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0db21ed3-ff02-46c8-94e8-629255887a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "# model = \"tiiuae/falcon-7b-instruct\"\n",
    "model = 'gpt2-large'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "def chat(prompt, kwargs):\n",
    "    \"text-generation\"\n",
    "    sequences = pipeline(\n",
    "       prompt,\n",
    "        **kwargs,\n",
    "        # max_length=max_length,\n",
    "        # do_sample=do_sample,\n",
    "        # top_k=top_k,\n",
    "        # num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    return [seq['generated_text'] for seq in sequences]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eee8b3-b154-4b3c-9654-c8d75e44e2c3",
   "metadata": {},
   "source": [
    "## Falcon: Completar Textos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a79613fe-3e2e-427c-988e-1ba1342fa75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.5 s, sys: 0 ns, total: 17.5 s\n",
      "Wall time: 4.43 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Who was the first man to step on the moon? He was a German, of course! The first man to walk upright on land, which happens to be us!\"\\n\\n\"The man who became a star?\"\\n\\n\"Of course,']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prompt = 'Who was the first man to step on the moon?'\n",
    "kwargs = {\n",
    "    'truncation': True,\n",
    "    'max_length':50,\n",
    "    'num_return_sequences':1,    \n",
    "}\n",
    "chat(prompt, kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8e2c8ee8-31ac-4789-aa25-ac5219f6f8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"The new product for sale is 『Lightning Stone』. It's an item that can be acquired, but for me, it's a new status I'm trying to work on!\\n\\nAfter a few days, I took off the top\"]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = 'The new product for sale is '\n",
    "kwargs = {\n",
    "    'truncation': True,\n",
    "    'max_length':50,\n",
    "    'num_return_sequences':1,    \n",
    "}\n",
    "chat(prompt, kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07a2c7f3-b935-4484-817b-d1e5741897e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 26s, sys: 2min 11s, total: 3min 38s\n",
      "Wall time: 2min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Who was the first man to step on the moon?\\nThe first man to step on the moon was Neil Armstrong on July 20, 1969.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prompt = 'Who was the first man to step on the moon?'\n",
    "kwargs = {\n",
    "    'truncation': True,\n",
    "    'max_length':200,\n",
    "    'num_return_sequences':1,    \n",
    "}\n",
    "chat(prompt, kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce44df0d-bd45-48a2-84e8-e5ff389bc046",
   "metadata": {},
   "source": [
    "## Falcon: Chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66c58744-a632-4118-8305-7c64ef24f84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 12s, sys: 9min 20s, total: 15min 32s\n",
      "Wall time: 11min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'role': 'system',\n",
       "   'content': 'you are a historian professor, with formal and calm temper, who makes jokes to explain complex subjects'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Professor, can you explain the principles of the French Revolution in three sentences?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': ' Sure! The French Revolution was a period of radical social and political change in France from 1789 to 1799. It was characterized by the collapse of the Bourbon monarchy, the rise of radical political factions, and the eventual rise of Napoleon Bonaparte. The revolution led to the establishment of the First French Republic, the adoption of the French Constitution, and the implementation of revolutionary principles such as liberty, equality, and fraternity.\\nUser: '}]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prompt = [\n",
    "    {\n",
    "        \"role\":\"system\",\n",
    "        \"content\":\"you are a historian professor, with formal and calm temper, who makes jokes to explain complex subjects\",\n",
    "    },{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Professor, can you explain the principles of the French Revolution in three sentences?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "kwargs = {\n",
    "    'truncation': True,\n",
    "    'max_length': 500,\n",
    "    'num_return_sequences':1,    \n",
    "}\n",
    "# text_inputs (`str`, `List[str]`, List[Dict[str, str]], or `List[List[Dict[str, str]]]`):\n",
    "# One or several prompts (or one list of prompts) to complete. If strings or a list of string are\n",
    "# passed, this pipeline will continue each prompt. Alternatively, a \"chat\", in the form of a list\n",
    "# of dicts with \"role\" and \"content\" keys, can be passed, or a list of such chats. When chats are passed,\n",
    "# the model's chat template will be used to format them before passing them to the model.\n",
    "chat(prompt, kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01c6394-c9dd-4904-934c-020d8ff2f08e",
   "metadata": {},
   "source": [
    "# Modelos Pagos: Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c3eebc0d-c288-4008-b15b-e8c1dff72b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# Cada um deve criar o seu proprio .env na raiz do repositorio\n",
    "# Esse .env deve ter os pares de chave=valor\n",
    "# GEMINI_KEY\n",
    "# OPENAI_KEY\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d0f0c87a-dfaa-482c-8520-0f28a2ca73d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The French Revolution was driven by a rejection of absolute monarchy and the feudal system, advocating for liberty, equality, and fraternity. It sought to establish a representative government based on the will of the people and abolish privileges enjoyed by the aristocracy. This revolution, fueled by economic hardship and Enlightenment ideals, aimed to create a more just and equitable society for all citizens. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir a chave de API do Gemini (use a chave fornecida pela sua conta)\n",
    "genai.configure(api_key=os.environ[\"GEMINI_KEY\"])\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(\"Professor, can you explain the principles of the French Revolution in three sentences?\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f0bc26-ca66-457b-bc5a-40aa58e70079",
   "metadata": {},
   "source": [
    "# Resumo Simples de Notícias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54643246-a146-4e74-ab64-78dac72b8171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumo gerado pelo LLM:\n",
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"<RESUMO>\\nO governo federal anunciou um novo pacote econ\\u00f4mico para estimular o crescimento das pequenas e m\\u00e9dias empresas, incluindo incentivos fiscais, redu\\u00e7\\u00e3o de burocracia e acesso facilitado ao cr\\u00e9dito, com o objetivo de impulsionar a retomada econ\\u00f4mica ap\\u00f3s a pandemia. \\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"index\": 0,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 214,\n",
      "        \"candidates_token_count\": 56,\n",
      "        \"total_token_count\": 270\n",
      "      }\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# Notícia copiada do portal de notícias (exemplo de notícia)\n",
    "noticia = \"\"\"\n",
    "O governo federal anunciou hoje um novo pacote econômico que visa estimular o crescimento das pequenas e médias empresas. \n",
    "O pacote inclui uma série de medidas de incentivo fiscal, redução de burocracia e facilitação de acesso a crédito. \n",
    "O presidente declarou que essas medidas são essenciais para a retomada econômica do país, principalmente após o impacto negativo da pandemia. \n",
    "Empresários do setor de tecnologia e serviços mostraram-se otimistas, mas ainda aguardam detalhes sobre a implementação das medidas.\n",
    "\"\"\"\n",
    "\n",
    "# Criando o prompt utilizando o princípio de Exemplos (few-shot prompting)\n",
    "prompt = f\"\"\"\n",
    "Resuma a <NOTICIA> em até 2 sentenças com os principais pontos da noticia.\n",
    "Aqui está um exemplo de resumo:\n",
    "\n",
    "<NOTICIA>\n",
    "\"A empresa X lançou um novo smartphone no mercado.\"\n",
    "###\n",
    "<RESUMO>\n",
    "\"A empresa X anunciou o lançamento de um novo smartphone, trazendo inovações tecnológicas e maior duração de bateria.\"\n",
    "\n",
    "Agora, faça o resumo da noticia abaixo:\n",
    "<NOTICIA>\n",
    "\"{noticia}\"\n",
    "###\n",
    "<RESUMO>\n",
    "\"\"\"\n",
    "\n",
    "# Executando o prompt com o modelo Gemini\n",
    "# Definir a chave de API do Gemini (use a chave fornecida pela sua conta)\n",
    "genai.configure(api_key=os.environ[\"GEMINI_KEY\"])\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "# Exibindo a resposta gerada\n",
    "print(\"Resumo gerado pelo LLM:\")\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c4f38b17-7f75-4eaa-af5c-336be43ef240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<RESUMO>\\nO governo federal anunciou um novo pacote econômico para estimular o crescimento das pequenas e médias empresas, incluindo incentivos fiscais, redução de burocracia e acesso facilitado ao crédito, com o objetivo de impulsionar a retomada econômica após a pandemia. \\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3175db56-a3d1-474e-8703-5b0a4462cefd",
   "metadata": {},
   "source": [
    "# Modelos Pagos: GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ac45227f-ba3f-4515-aa5f-40b6207fc1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "# OPENAI_KEY é uma chave que deve ser colocada no aquivo .env na raiz do notebook\n",
    "client = OpenAI(\n",
    "    api_key=os.environ['OPENAI_KEY']\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ],\n",
    "    stream=False,\n",
    "    \n",
    ")\n",
    "completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3d9b82-87ca-47b1-8713-07bd551770f9",
   "metadata": {},
   "source": [
    "# Métrica BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d59b8e00-6b75-4cd5-9a5a-35b125a00740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3862752974508188"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sacrebleu.metrics import BLEU\n",
    "bleu_scorer = BLEU()\n",
    "\n",
    "hypothesis = \"to make people trustworthy you need to trust them\"\n",
    "reference = \"the way to make people trustworthy is to trust them\"\n",
    "\n",
    "score = bleu_scorer.sentence_score(\n",
    "    hypothesis=hypothesis,\n",
    "    references=[reference],\n",
    ")\n",
    "\n",
    "score.score/100 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf57b3b4-11ce-4c17-a586-765ae4e24010",
   "metadata": {},
   "source": [
    "# Métrica ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7d68c0bc-74ea-467a-812d-f1a5efab043c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-L-F 0.7058823479584776\n",
      "ROUGE-L-R 0.6666666666666666\n",
      "ROUGE-L-P 0.75\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "hypothesis = \"to make people trustworthy you need to trust them\"\n",
    "reference = \"the way to make people trustworthy is to trust them\"\n",
    "\n",
    "score = rouge_scorer.get_scores(\n",
    "    hyps=hypothesis,\n",
    "    refs=reference,\n",
    ")\n",
    "print('ROUGE-L-F', score[0][\"rouge-l\"][\"f\"])\n",
    "print('ROUGE-L-R', score[0][\"rouge-l\"]['r'])\n",
    "print('ROUGE-L-P', score[0][\"rouge-l\"]['p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a653629-f748-42f9-b2c4-0f8f823df5a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
